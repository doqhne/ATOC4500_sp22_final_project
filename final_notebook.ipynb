{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325e7b1a-6752-4e68-94f0-66453835e768",
   "metadata": {},
   "source": [
    "## **ATOC4500 Data Science Lab: Final Project**\n",
    "## **Using rapid ice loss events to predict when CESM1 ensemble members go ice free**\n",
    "#### **Author: Daphne Quint, daqu2831@colorado.edu**\n",
    "#### **Last updated: April 14, 2022**\n",
    "\n",
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8109c09-44e4-4b1e-bce5-ffaf336a87a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84337a16-1c71-4058-a049-e9b290f3d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de63e6-6768-4cb0-95ae-d03739d866cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa58a44-a6e9-4066-b02c-2566128a69aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_year(data, member):\n",
    "    '''\n",
    "    Finds the year 1 member goes below 1 million square km\n",
    "    '''\n",
    "    \n",
    "    data_ = data.sel(member=member)\n",
    "    \n",
    "    year = 2020\n",
    "    for i in data_:\n",
    "        if i>1:\n",
    "            year += 1\n",
    "        else:\n",
    "            return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73e1f47-5d31-4ba3-94ca-cc08d2dcdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(month):\n",
    "    #### find ice free year for that month\n",
    "    \n",
    "    ###first find 5 year mean\n",
    "    \n",
    "    # define September SIE\n",
    "    SIE_sept = SIE['CESM1'].sel(time=SIE['time.month']==month).sel(member=np.arange(1, 41, 1))\n",
    "\n",
    "    # find the 5 year running mean\n",
    "    five_year_mean = SIE_sept*0\n",
    "\n",
    "    for i in range(1, 41):\n",
    "        five_year_mean[i-1] = SIE_sept.sel(member=i).rolling(time=5).mean()\n",
    "\n",
    "    five_year_mean = five_year_mean.sel(time=slice('2020', '2100'))\n",
    "    \n",
    "    ### then find the ice free year\n",
    "    ice_free_year = []\n",
    "    for i in range(1, 41):\n",
    "        ice_free_year.append(find_year(five_year_mean, i))\n",
    "    ice_free_year = np.array(ice_free_year)\n",
    "    \n",
    "    #### find max amt of ice lost in the month\n",
    "    \n",
    "    ice_lost_max = []\n",
    "    for i in range(1, 41):\n",
    "        ice_lost_max.append(float(nb_ext_data['RILE Indicator'].sel(member=i).sel(month=month).min().values))\n",
    "    ice_lost_max = np.array(ice_lost_max)\n",
    "    \n",
    "    #### find longest duration for the month\n",
    "    \n",
    "    length_max = []\n",
    "    for i in range(1, 41):\n",
    "        length_max.append(float(length_data['Length'].sel(member=i).sel(month=month).max().values))\n",
    "    length_max = np.array(length_max)\n",
    "    \n",
    "    #### create dataframe\n",
    "    \n",
    "    member = pd.DataFrame(data=np.arange(1, 41), columns=['Member'])\n",
    "    month = pd.DataFrame(data=(np.zeros(40)+month), columns=['Month'])\n",
    "    ice_free_yr_df = pd.DataFrame(data=ice_free_year, columns=['Ice Free Year'])\n",
    "    ice_lost_max_df = pd.DataFrame(data=ice_lost_max, columns=['Max Ice Lost'])*-1\n",
    "    length_max_df = pd.DataFrame(data=length_max, columns=['Longest Duration'])\n",
    "    \n",
    "    this_month_df = pd.concat([member, month, ice_free_yr_df, ice_lost_max_df, length_max_df], axis=1)\n",
    "    \n",
    "    return this_month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1249db24-92b9-47c4-b717-dc994b83f24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_holdout_data(x, y, verbose):\n",
    "    \"\"\"Perform a 80/20 test-train split (80% of data is training, 20% is testing). Split is randomized with each call.\"\"\"\n",
    "    random_state = randint(0,1000)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=random_state)\n",
    "    if verbose==True:\n",
    "        print(\"Prior to scaling and rebalacing...\")\n",
    "        print(\"Shape of training predictors: \"+str(np.shape(x_train)))\n",
    "        print(\"Shape of testing predictors: \"+str(np.shape(x_test)))\n",
    "        print(\"Shape of training predictands: \"+str(np.shape(y_train)))\n",
    "        print(\"Shape of testing predictands: \"+str(np.shape(y_test)))\n",
    "        print(\" \")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011bcf47-8a5d-4439-a2da-c0b2d43c1773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Scale training data so that model reaches optimized weights much faster. \n",
    "    \n",
    "    *All data that enters the model should use the same scaling used to scale the training data.*\n",
    "    Thus, we also perform scaling on testing data for validation later. \n",
    "    Additionally, we return the scaler used to scale any other future input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler() # normalize \n",
    "    x_train_scaled = pd.DataFrame(data=scaler.fit_transform(x_train),index=x_train.index,columns=x_train.columns) \n",
    "    x_test_scaled = pd.DataFrame(data=scaler.transform(x_test),index=x_test.index,columns=x_test.columns)\n",
    "    \n",
    "    return scaler, x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b7fe30-eaaa-4297-a035-496d8012e1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balance_data(x,y,verbose):\n",
    "    \"\"\"Resample data ensure model is not biased towards a particular outcome of precip or no precip.\"\"\"\n",
    "    # Combine again to one dataframe to ensure both the predictor and predictand are resampled from the same \n",
    "    # observations based on predictand outcomes. \n",
    "    dataset = pd.concat([x, y],axis=1)\n",
    "\n",
    "    # Separating classes\n",
    "    early = dataset[dataset['early_bin'] == 1]\n",
    "    not_early = dataset[dataset['early_bin'] == 0]\n",
    "\n",
    "    random_state = randint(0,1000)\n",
    "    oversample = resample(early, \n",
    "                           replace=True, \n",
    "                           n_samples=len(not_early), #set the number of samples to equal the number of the majority class\n",
    "                           random_state=random_state)\n",
    "\n",
    "    # Returning to new training set\n",
    "    oversample_dataset = pd.concat([not_early, oversample])\n",
    "\n",
    "    # reseparate oversampled data into X and y sets\n",
    "    x_bal = oversample_dataset.drop(['early_bin'], axis=1)\n",
    "    y_bal = oversample_dataset['early_bin']\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"After scaling and rebalacing...\")\n",
    "        print(\"Shape of predictors: \"+str(np.shape(x_bal)))\n",
    "        print(\"Shape of predictands: \"+str(np.shape(y_bal)))\n",
    "        print(\" \")\n",
    "    \n",
    "    return x_bal, y_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6c7ac5-6653-41ea-bbc7-b5ea288fa088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataprep_pipeline(x, y, verbose):\n",
    "    \"\"\" Combines all the functions defined above so that the user only has to \n",
    "    call one function to do all data pre-processing. \"\"\"\n",
    "    # verbose=True prints the shapes of input & output data\n",
    "\n",
    "    # split into training & testing data\n",
    "    x_train, x_test, y_train, y_test = define_holdout_data(x, y, verbose) \n",
    "\n",
    "    # perform feature scaling\n",
    "    scaler, x_train_scaled, x_test_scaled = scale_data(x_train, x_test)\n",
    "\n",
    "    # rebalance according to outcomes (i.e., the number of precipitating \n",
    "    # observations & non-precipitating outcomes should be equal)\n",
    "    if verbose==True:\n",
    "        print(\"for training data... \")\n",
    "    x_train_bal, y_train_bal = balance_data(x_train_scaled, y_train, verbose)\n",
    "    if verbose==True:\n",
    "        print(\"for testing data... \")\n",
    "    x_test_bal, y_test_bal = balance_data(x_test_scaled, y_test, verbose)\n",
    "    \n",
    "    return x_train_bal, y_train_bal, x_test_bal, y_test_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21cadbdb-d86f-449d-8953-899ec4b88edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bin_metrics(x, y):\n",
    "    \"\"\"Prints accuracy and recall metrics for evaluating \n",
    "    classification predictions.\"\"\"\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(x, y)\n",
    "    recall = metrics.recall_score(x, y)\n",
    "\n",
    "    print('Accuracy:', round(accuracy, 4))\n",
    "    print('Recall:', round(recall, 4))\n",
    "    \n",
    "    return accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162157bf-c037-454f-9b3c-6c611247812b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_cm(x, y):\n",
    "    \"\"\"Plots the confusion matrix to visualize true \n",
    "    & false positives & negatives\"\"\"\n",
    "    cm = confusion_matrix(x, y)\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(x), index = np.unique(x))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25}, fmt='g')# font size\n",
    "    plt.ylim([0, 2])\n",
    "    plt.xticks([0.5, 1.5], ['Negatives','Positives'])\n",
    "    plt.yticks([0.5, 1.5], ['Negatives','Positives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccc03525-4704-476a-8770-2f216fd0855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_atmos_conditions_precip(index='rand'):\n",
    "    \"\"\"\n",
    "    Function returns atmospheric conditions in a dataframe as well as the scaled\n",
    "    conditions in a numpy array so that they output a prediction in the model.\n",
    "    \n",
    "    If no input is passed, the function will randomly generate an in index to \n",
    "    choose from those observations in some training data with precipitation. \n",
    "    Otherwise, an integer index between 0 and 200 should be passed.\n",
    "    \"\"\"\n",
    "    # First, perform a test-train split\n",
    "    x_train, x_test, y_train, _ = define_holdout_data(x, y, verbose=False) \n",
    "\n",
    "    # perform feature scaling\n",
    "    _, x_train_scaled, _ = scale_data(x_train, x_test)\n",
    "\n",
    "    # this is what will go into the model to output a prediction\n",
    "    if index=='rand':\n",
    "        index = randint(0,len(y_train[y_train==1].index)) \n",
    "    precipindex = y_train[y_train==1].index.values[index]\n",
    "    testpredictor = x_train_scaled.loc[precipindex] \n",
    "    \n",
    "    return sept_df.iloc[precipindex], testpredictor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a7517-e004-491c-b0fc-c9e7c4322903",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Step 1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f823bd6-5e8d-40c2-8fd9-ad533dade7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/daphne/Documents/School/research/icefreeproject/Data/'\n",
    "\n",
    "# Amount of sea ice lost and Sea ice extent data for each RILE\n",
    "nb_ext_data = xr.open_dataset(data_path+'RILE_nbext_CESM.nc')\n",
    "\n",
    "# length data (consecutive years in a row there is a rile for that month)\n",
    "length_data = xr.open_dataset(data_path+'CESM_rile_length.nc')\n",
    "\n",
    "# extent data - can be used to find ice free year for each member\n",
    "SIE = xr.open_dataset(data_path+'CLIVAR_SIE_1850_2100_RCP85.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5656f-c160-41d7-aba1-48bdbb02251e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Step 2: Munge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f49110-ee7d-46b7-8c26-253dc3cc25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = create_df(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e3a12e-d557-4161-8251-f5fa59c6674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sept_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111a806-263b-4fa4-bfd4-6d796d8eae6f",
   "metadata": {},
   "source": [
    "## Step 3: Apply Data Science Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5459f-fb89-4b52-85a5-91627026cb80",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d324a2-10f6-4c5b-81ed-d3cea1f92286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature that indicates whether or not the member goes ice free before 2043\n",
    "sept_df['early_bin'] = np.array(sept_df['Ice Free Year']<=2043).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1b9d1d7-f0f1-49c0-b093-d1c1874b177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that we will use to predict ice free year\n",
    "x = sept_df.drop(['Month','Member', 'Ice Free Year', 'early_bin'],axis=1)\n",
    "\n",
    "# what we are trying to predict- early ice free year\n",
    "y = sept_df.drop(['Month','Member', 'Longest Duration', 'Max Ice Lost', 'Ice Free Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea640308-3e62-407f-b4fa-c8e8a76d61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "early_bin\n",
       "0            35\n",
       "1             5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "899a924f-fef1-41ff-a1ce-0549bac58f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior to scaling and rebalacing...\n",
      "Shape of training predictors: (32, 2)\n",
      "Shape of testing predictors: (8, 2)\n",
      "Shape of training predictands: (32, 1)\n",
      "Shape of testing predictands: (8, 1)\n",
      " \n",
      "for training data... \n",
      "After scaling and rebalacing...\n",
      "Shape of predictors: (58, 2)\n",
      "Shape of predictands: (58,)\n",
      " \n",
      "for testing data... \n",
      "After scaling and rebalacing...\n",
      "Shape of predictors: (12, 2)\n",
      "Shape of predictands: (12,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f3bdbe1-5f85-4bb2-a0a0-4ff691027655",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(x_train_bal, y_train_bal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2394b408-0275-4505-b0b0-948f243a1d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4167\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(x_test_bal)\n",
    "lr_acc, lr_rec = bin_metrics(y_test_bal, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d224a3b-f097-4e9c-b10b-2b9012a47cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics:\n",
      "Accuracy: 0.6897\n",
      "Recall: 0.6552\n",
      " \n",
      "Testing metrics:\n",
      "Accuracy: 0.4167\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training metrics:\")\n",
    "pred_train= lr.predict(x_train_bal) \n",
    "bin_metrics(y_train_bal,pred_train);\n",
    "\n",
    "print(\" \")\n",
    "print(\"Testing metrics:\")\n",
    "bin_metrics(y_test_bal, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b4b9850-2afe-4b3d-aab2-b7884a35d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "origvals, testpredictor = rand_atmos_conditions_precip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26305abf-1f95-4963-bc3a-70967a91878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conditions are: \n",
      "Member                30.000000\n",
      "Month                  9.000000\n",
      "Ice Free Year       2046.000000\n",
      "Max Ice Lost           0.329655\n",
      "Longest Duration      12.000000\n",
      "early_bin              0.000000\n",
      "Name: 29, dtype: float64\n",
      " \n",
      "There is a 48.33% chance a member will go ice free 2043 or before given those conditions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daphne/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_prediction = lr.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
    "print(\"The conditions are: \")\n",
    "print(origvals)\n",
    "print(\" \")\n",
    "print(\"There is a {0:.{digits}f}% chance a member will go ice free 2043 or before given those conditions.\".format(lr_prediction, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179558b-294d-4ae2-ab88-5454e7c066cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb35fef-7022-4d46-86cf-3c9595041e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c5a314-933a-4662-b6d5-e8f44638f69f",
   "metadata": {},
   "source": [
    "## Step 4: Present graphs visually using 2-3 graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa6437-4d78-4036-9a56-a46d9bd029d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b4504a-3424-4726-8e41-92f1b69220d7",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c02323-efb1-4880-abcc-06e5db040547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
